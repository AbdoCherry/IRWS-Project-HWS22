{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44ef7bd-3fed-4378-866c-a9a14768d2e8",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6743d5-cb4f-4d10-8261-76dd77f5d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbaf1ca-9c54-4f9a-a993-52f9550a9d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>rel_docs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[cultiv, agricultur, maiz, corn, fruit, wheat,...</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>[572, 627, 678, 903, 1193, 1542, 1634, 3751, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[reptil, lizard, salamand, fossil, frog, prehi...</td>\n",
       "      <td>Amphibians and Reptiles</td>\n",
       "      <td>[621, 809, 1380, 6641, 8311, 8937, 13134, 1446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>[astronom, astronomi, astrophysicist, mathemat...</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>[39, 308, 580, 664, 736, 748, 791, 798, 799, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>[aviat, airfield, airport, aerospac, aircraft,...</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>[849, 852, 1293, 1902, 1942, 2039, 2075, 2082,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[actor, cast, screenwrit, filmmak, film, actre...</td>\n",
       "      <td>Biography/WikiProject Actors and Filmmakers</td>\n",
       "      <td>[344, 676, 808, 872, 1247, 1806, 1828, 2083, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   keywords  \\\n",
       "query_id                                                      \n",
       "84        [cultiv, agricultur, maiz, corn, fruit, wheat,...   \n",
       "111       [reptil, lizard, salamand, fossil, frog, prehi...   \n",
       "265       [astronom, astronomi, astrophysicist, mathemat...   \n",
       "323       [aviat, airfield, airport, aerospac, aircraft,...   \n",
       "396       [actor, cast, screenwrit, filmmak, film, actre...   \n",
       "\n",
       "                                                title  \\\n",
       "query_id                                                \n",
       "84                                        Agriculture   \n",
       "111                           Amphibians and Reptiles   \n",
       "265                                         Astronomy   \n",
       "323                                          Aviation   \n",
       "396       Biography/WikiProject Actors and Filmmakers   \n",
       "\n",
       "                                                   rel_docs  \n",
       "query_id                                                     \n",
       "84        [572, 627, 678, 903, 1193, 1542, 1634, 3751, 3...  \n",
       "111       [621, 809, 1380, 6641, 8311, 8937, 13134, 1446...  \n",
       "265       [39, 308, 580, 664, 736, 748, 791, 798, 799, 1...  \n",
       "323       [849, 852, 1293, 1902, 1942, 2039, 2075, 2082,...  \n",
       "396       [344, 676, 808, 872, 1247, 1806, 1828, 2083, 2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read preprocessed queries in pandas dataframe\n",
    "queries = pd.read_csv('data/preprocessed_query_data.csv')\n",
    "queries['keywords'] = queries['keywords'].str.strip('][').str.replace(\"'\", \"\").str.split(', ')\n",
    "queries = queries.set_index('id')\n",
    "queries.index.name = 'query_id'\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2100f0d-2785-46ff-a1c9-d98d3d0650e8",
   "metadata": {},
   "source": [
    "## 1) TF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99132989-50ef-44a4-8b22-e3972cd7422c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 2 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 3 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 4 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 5 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 6 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 7 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 8 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 9 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 39 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 40 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 41 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 42 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 43 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 44 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 45 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 46 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 47 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 48 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 49 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 50 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 51 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 52 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 53 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 54 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 55 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 56 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 57 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 58 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 59 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 60 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 61 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 62 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 63 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 64 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n",
      "chunk 65 / 65: count words... get term counts... calculate term frequencies...  normalize and apply logarithmic decay... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write to file.\n"
     ]
    }
   ],
   "source": [
    "query_terms = (list(set([a for b in queries['keywords'].tolist() for a in b])))\n",
    "\n",
    "# initiate count vectorizer (using only words that appear in the query for performance reasons)\n",
    "count_vectorizer = CountVectorizer(vocabulary=query_terms)\n",
    "\n",
    "# read logfile to look for last successfully processed chunk\n",
    "logfile_path = 'data/tf-idf_chunks_log.txt'\n",
    "try:\n",
    "    f = open(logfile_path, \"r\")\n",
    "    last_chunk_idx = int(f.read())\n",
    "    f.close()\n",
    "except FileNotFoundError:\n",
    "    last_chunk_idx = -1\n",
    "\n",
    "# iterate over chunks to get term frequencies of every document\n",
    "corpus_iterator = pd.read_csv('data/preprocessed_corpus.csv', index_col='id', chunksize=100000)\n",
    "for i, corpus_df in enumerate(corpus_iterator):\n",
    "    # skip chunk if preprocessing is already done for this chunk\n",
    "    if i <= last_chunk_idx:\n",
    "        continue\n",
    "        \n",
    "    print(f'chunk {i+1} / 65: ', end='')\n",
    "    \n",
    "    # drop empty documents\n",
    "    corpus_df = corpus_df.dropna()\n",
    "    corpus_df.index.name = 'page_id'\n",
    "    \n",
    "    # get count of words per document\n",
    "    print('count words... ', end='')\n",
    "    total_word_counts = corpus_df['plain'].str.split(' ').str.len().rename('count')\n",
    "    \n",
    "    # get term counts (using only words that appear in the query for performance reasons)\n",
    "    print('get term counts... ', end='')\n",
    "    term_counts = count_vectorizer.fit_transform(corpus_df['plain'])\n",
    "    terms = count_vectorizer.get_feature_names_out()\n",
    "    term_counts_df = pd.DataFrame(term_counts.toarray(), columns=terms, index=corpus_df.index)\n",
    "    \n",
    "    # calculate term frequencies\n",
    "    print('calculate term frequencies...  ', end='')\n",
    "    term_frequencies = term_counts_df.div(total_word_counts, axis=0)\n",
    "    \n",
    "    # normalize and apply logarithmic decay\n",
    "    print('normalize and apply logarithmic decay... ', end='')\n",
    "    #max_freqs = term_frequencies.max(axis=1).copy()\n",
    "    #max_freqs = np.log10(max_freqs)\n",
    "    #max_freqs = max_freqs + 1\n",
    "    term_frequencies = np.log10(term_frequencies)\n",
    "    term_frequencies = term_frequencies + 1\n",
    "    term_frequencies = term_frequencies.replace([np.inf, -np.inf], -999999)\n",
    "    #term_frequencies = term_frequencies.div(max_freqs, axis=0)\n",
    "    \n",
    "    # writing file\n",
    "    print('write to file.')\n",
    "    # Set writing mode to append after first chunk\n",
    "    mode = 'w' if i == 0 else 'a'\n",
    "    # Add header if it is the first chunk\n",
    "    header = i == 0\n",
    "    \n",
    "    term_frequencies.to_csv(\n",
    "        \"data/term_frequencies.csv\",\n",
    "        header=header,\n",
    "        mode=mode)\n",
    "    \n",
    "    # write chunk index to log file\n",
    "    f = open(logfile_path, \"w\")\n",
    "    f.write(str(i))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47e4f1-2db4-4786-a822-734ea66f81bc",
   "metadata": {},
   "source": [
    "## 2) IDF vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba502034-80d1-4ded-a753-466293e8623c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 / 65\n",
      "chunk 2 / 65\n",
      "chunk 3 / 65\n",
      "chunk 4 / 65\n",
      "chunk 5 / 65\n",
      "chunk 6 / 65\n",
      "chunk 7 / 65\n",
      "chunk 8 / 65\n",
      "chunk 9 / 65\n",
      "chunk 10 / 65\n",
      "chunk 11 / 65\n",
      "chunk 12 / 65\n",
      "chunk 13 / 65\n",
      "chunk 14 / 65\n",
      "chunk 15 / 65\n",
      "chunk 16 / 65\n",
      "chunk 17 / 65\n",
      "chunk 18 / 65\n",
      "chunk 19 / 65\n",
      "chunk 20 / 65\n",
      "chunk 21 / 65\n",
      "chunk 22 / 65\n",
      "chunk 23 / 65\n",
      "chunk 24 / 65\n",
      "chunk 25 / 65\n",
      "chunk 26 / 65\n",
      "chunk 27 / 65\n",
      "chunk 28 / 65\n",
      "chunk 29 / 65\n",
      "chunk 30 / 65\n",
      "chunk 31 / 65\n",
      "chunk 32 / 65\n",
      "chunk 33 / 65\n",
      "chunk 34 / 65\n",
      "chunk 35 / 65\n",
      "chunk 36 / 65\n",
      "chunk 37 / 65\n",
      "chunk 38 / 65\n",
      "chunk 39 / 65\n",
      "chunk 40 / 65\n",
      "chunk 41 / 65\n",
      "chunk 42 / 65\n",
      "chunk 43 / 65\n",
      "chunk 44 / 65\n",
      "chunk 45 / 65\n",
      "chunk 46 / 65\n",
      "chunk 47 / 65\n",
      "chunk 48 / 65\n",
      "chunk 49 / 65\n",
      "chunk 50 / 65\n",
      "chunk 51 / 65\n",
      "chunk 52 / 65\n",
      "chunk 53 / 65\n",
      "chunk 54 / 65\n",
      "chunk 55 / 65\n",
      "chunk 56 / 65\n",
      "chunk 57 / 65\n",
      "chunk 58 / 65\n",
      "chunk 59 / 65\n",
      "chunk 60 / 65\n",
      "chunk 61 / 65\n",
      "chunk 62 / 65\n",
      "chunk 63 / 65\n",
      "chunk 64 / 65\n",
      "chunk 65 / 65\n"
     ]
    }
   ],
   "source": [
    "# read logfile to look for last successfully processed chunk\n",
    "logfile_path2 = 'data/tf-idf_chunks_log2.txt'\n",
    "try:\n",
    "    f = open(logfile_path2, \"r\")\n",
    "    last_chunk_idx = int(f.read())\n",
    "    f.close()\n",
    "except FileNotFoundError:\n",
    "    last_chunk_idx = -1\n",
    "    \n",
    "# iterate over tf vectors in chunks and generate document counts\n",
    "tf_iterator = pd.read_csv('data/term_frequencies.csv', index_col='page_id', chunksize=100000)\n",
    "for i, tf in enumerate(tf_iterator):\n",
    "    \n",
    "    if i <= last_chunk_idx:\n",
    "        continue\n",
    "    \n",
    "    print(f'chunk {i+1} / 65')\n",
    "    \n",
    "    doc_counts_chunk = tf.copy()\n",
    "    doc_counts_chunk = doc_counts_chunk.replace([-999999], 0)\n",
    "    doc_counts_chunk = doc_counts_chunk.astype(bool).astype(int)\n",
    "    doc_counts_chunk = doc_counts_chunk.sum()\n",
    "    doc_counts_chunk.name = 'count'\n",
    "    doc_counts_chunk.index.name = 'term'\n",
    "    if i == 0:\n",
    "        doc_counts_chunk.to_csv('data/doc_counts.csv')\n",
    "    else:\n",
    "        doc_counts = pd.read_csv('data/doc_counts.csv', index_col='term')\n",
    "        doc_counts = doc_counts.squeeze()\n",
    "        doc_counts = doc_counts.add(doc_counts_chunk, axis=0)\n",
    "        doc_counts.to_csv('data/doc_counts.csv')\n",
    "        \n",
    "    # write chunk index to log file\n",
    "    f = open(logfile_path2, \"w\")\n",
    "    f.write(str(i))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1aa69d1-43cf-44b0-ba25-96d02160e76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculat idf from document counts\n",
    "doc_counts = pd.read_csv('data/doc_counts.csv', index_col='term')\n",
    "doc_counts = doc_counts.squeeze()\n",
    "N = 6475473\n",
    "idf = N / doc_counts\n",
    "idf = np.log10(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccddea2-6c8f-4cdc-aa17-114db262cf0c",
   "metadata": {},
   "source": [
    "## TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f48cb2-1460-4b27-b5cd-7b294e2001a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 52 / 65\n",
      "chunk 53 / 65\n",
      "chunk 54 / 65\n",
      "chunk 55 / 65\n",
      "chunk 56 / 65\n",
      "chunk 57 / 65\n",
      "chunk 58 / 65\n",
      "chunk 59 / 65\n",
      "chunk 60 / 65\n",
      "chunk 61 / 65\n",
      "chunk 62 / 65\n",
      "chunk 63 / 65\n",
      "chunk 64 / 65\n",
      "chunk 65 / 65\n"
     ]
    }
   ],
   "source": [
    "# read logfile to look for last successfully processed chunk\n",
    "logfile_path3 = 'data/tf-idf_chunks_log3.txt'\n",
    "try:\n",
    "    f = open(logfile_path3, \"r\")\n",
    "    last_chunk_idx = int(f.read())\n",
    "    f.close()\n",
    "except FileNotFoundError:\n",
    "    last_chunk_idx = -1\n",
    "    \n",
    "# iterate over tf vectors in chunks and generate tf-idf vectors\n",
    "tf_iterator = pd.read_csv('data/term_frequencies.csv', index_col='page_id', chunksize=100000)\n",
    "for i, tf_chunk in enumerate(tf_iterator):\n",
    "    \n",
    "    if i <= last_chunk_idx:\n",
    "        continue\n",
    "    \n",
    "    print(f'chunk {i+1} / 65')\n",
    "    \n",
    "    # in case a document appears twice per chunk, drop duplications\n",
    "    tf_chunk = tf_chunk[~tf_chunk.index.duplicated(keep='first')]\n",
    "    \n",
    "    tfidf_chunk = tf_chunk.multiply(idf, axis=1)\n",
    "                       \n",
    "    # Set writing mode to append after first chunk\n",
    "    mode = 'w' if i == 0 else 'a'\n",
    "    # Add header if it is the first chunk\n",
    "    header = i == 0\n",
    "    \n",
    "    tfidf_chunk.to_csv(\n",
    "        \"data/tfidf_doc.csv\",\n",
    "        header=header,\n",
    "        mode=mode)\n",
    "    \n",
    "    # write chunk index to log file\n",
    "    f = open(logfile_path3, \"w\")\n",
    "    f.write(str(i))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69446352-2039-4090-9ca6-5be6a35dc2a1",
   "metadata": {},
   "source": [
    "## TF-IDF vectors of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932f6c90-77a5-4f24-bb08-a1010c831b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_terms = (list(set([a for b in queries['keywords'].tolist() for a in b])))\n",
    "\n",
    "# initiate count vectorizer (using only words that appear in the query for performance reasons)\n",
    "count_vectorizer = CountVectorizer(vocabulary=query_terms)\n",
    "\n",
    "query_term_counts = count_vectorizer.fit_transform(queries['keywords'].str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04d15fe-826d-4d7a-8ecb-cb20283d4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_terms = count_vectorizer.get_feature_names_out()\n",
    "query_term_counts_df = pd.DataFrame(query_term_counts.toarray(), columns=query_terms, index=queries.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c0a0fb-e394-4dc0-af36-8207f277c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# term counts\n",
    "\n",
    "query_terms = (list(set([a for b in queries['keywords'].tolist() for a in b])))\n",
    "\n",
    "# initiate count vectorizer (using only words that appear in the query for performance reasons)\n",
    "count_vectorizer = CountVectorizer(vocabulary=query_terms)\n",
    "\n",
    "query_total_word_counts = queries['keywords'].str.len().rename('count')\n",
    "query_term_counts = count_vectorizer.fit_transform(queries['keywords'].str.join(' '))\n",
    "query_terms = count_vectorizer.get_feature_names_out()\n",
    "query_term_counts_df = pd.DataFrame(query_term_counts.toarray(), columns=query_terms, index=queries.index)\n",
    "\n",
    "# frequencies\n",
    "query_term_frequencies = query_term_counts_df.div(query_total_word_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ecbdd2-919a-4a17-9257-acc829a73f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = func(self.values, **kwargs)\n",
      "/opt/bwhpc/common/jupyter/tensorflow/2022-12-05/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: invalid value encountered in log10\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# normalize and apply logarithmic decay\n",
    "#max_query_freqs = query_term_frequencies.max(axis=1).copy()\n",
    "#max_query_freqs = np.log10(max_query_freqs)\n",
    "#max_query_freqs = max_query_freqs + 1\n",
    "query_term_frequencies = np.log10(query_term_frequencies)\n",
    "query_term_frequencies = query_term_frequencies + 1\n",
    "query_term_frequencies = query_term_frequencies.replace([np.inf, -np.inf], -999999)\n",
    "#query_term_frequencies = query_term_frequencies.div(max_query_freqs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dfcc407-5a91-4bc2-a95b-96ade909d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_counts = query_term_frequencies.copy()\n",
    "#query_counts = query_counts.astype(bool).astype(int)\n",
    "#query_counts = query_counts.sum()\n",
    "#query_counts.name = 'count'\n",
    "#query_counts.index.name = 'term'\n",
    "#query_counts = query_counts[query_counts != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04db0550-204b-425e-9812-096163d21967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = len(queries)\n",
    "#query_idf = N / query_counts\n",
    "#query_idf = np.log10(query_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd628dd-54fc-4af5-9636-d89d4389ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_tfidf = query_term_frequencies.multiply(query_idf, axis=1)\n",
    "query_tfidf = query_term_frequencies.multiply(idf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf4bd5c-fd8c-4d51-8e30-dcdf924fe931",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf.to_csv('data/tfidf_queries.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14606f-08b9-4af4-a13d-56f6fedaf8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
