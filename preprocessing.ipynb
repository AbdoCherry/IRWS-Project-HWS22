{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d83f0b-835f-4dc6-ad98-2458a5ae41f8",
   "metadata": {},
   "source": [
    "# Data Preprocsesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4194b204-97bd-4769-b0a4-63ae135a0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92ca95b-dcb3-4490-abff-c6df385eaedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('data/trec_corpus_20220301_plain.json') as read_from_file:\\n    with open('data/preprocessed_corputs.csv', 'a') as write_to_file:\\n        \\n        # write header of csv file\\n        write_to_file.write('id, text')\\n        doc = read_from_file.readline()\\n\\n        for i in range(5): # while doc:\\n            \\n            # parse json\\n            doc_parsed = json.loads(doc)\\n            doc_text = doc_parsed['title'] + ' ' + doc_parsed['plain']\\n            \\n            print(doc_parsed)\\n            print('\\n\\n############\\n\\n')\\n\\n            # do preprocessing\\n            preprocessed_text = 'test test test test test'\\n\\n            # write preprocessed document to file (append)\\n            write_to_file.write(f'{doc_id}, {preprocessed_text}\\n')\\n\\n            # read next line\\n            doc = read_from_file.readline()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open('data/trec_corpus_20220301_plain.json') as read_from_file:\n",
    "    with open('data/preprocessed_corputs.csv', 'a') as write_to_file:\n",
    "        \n",
    "        # write header of csv file\n",
    "        write_to_file.write('id, text')\n",
    "        doc = read_from_file.readline()\n",
    "\n",
    "        for i in range(5): # while doc:\n",
    "            \n",
    "            # parse json\n",
    "            doc_parsed = json.loads(doc)\n",
    "            doc_text = doc_parsed['title'] + ' ' + doc_parsed['plain']\n",
    "            \n",
    "            print(doc_parsed)\n",
    "            print('\\n\\n############\\n\\n')\n",
    "\n",
    "            # do preprocessing\n",
    "            preprocessed_text = 'test test test test test'\n",
    "\n",
    "            # write preprocessed document to file (append)\n",
    "            write_to_file.write(f'{doc_id}, {preprocessed_text}\\n')\n",
    "\n",
    "            # read next line\n",
    "            doc = read_from_file.readline()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae10a83-f8fa-462a-8a3d-52aab036c3f1",
   "metadata": {},
   "source": [
    "# Approach of Abda\n",
    "- Loading data\n",
    "- Preprocessing first 5 lines to save computation\n",
    "- Appending preprecessed data into a dictionary / dataframe \n",
    "- Saving finished data after preprocessing into csv or feather file for continuous analysis and evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731b8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0490c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>plain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12148915</td>\n",
       "      <td>Keith Osik</td>\n",
       "      <td>Keith Richard Osik (born October 22, 1968), is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16752449</td>\n",
       "      <td>Swansons Landing, Texas</td>\n",
       "      <td>Swansons Landing is a settlement and former in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31967453</td>\n",
       "      <td>Mike Potts</td>\n",
       "      <td>Mike or Michael Potts may refer to:\\n Michael ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47436994</td>\n",
       "      <td>Shuker</td>\n",
       "      <td>Shuker is a surname. Notable people with the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13924699</td>\n",
       "      <td>William Clark (inventor)</td>\n",
       "      <td>William Clark (17 March 1821 – 22 January 1880...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                     title  \\\n",
       "0  12148915                Keith Osik   \n",
       "1  16752449   Swansons Landing, Texas   \n",
       "2  31967453                Mike Potts   \n",
       "3  47436994                    Shuker   \n",
       "4  13924699  William Clark (inventor)   \n",
       "\n",
       "                                               plain  \n",
       "0  Keith Richard Osik (born October 22, 1968), is...  \n",
       "1  Swansons Landing is a settlement and former in...  \n",
       "2  Mike or Michael Potts may refer to:\\n Michael ...  \n",
       "3  Shuker is a surname. Notable people with the s...  \n",
       "4  William Clark (17 March 1821 – 22 January 1880...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check first stats of first 10 rows\n",
      "------------------------------------\n",
      "<bound method Series.sort_values of id       0\n",
      "title    0\n",
      "plain    0\n",
      "dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset -> Only first five rows\n",
    "df_prep = pd.read_json('data/trec_corpus_20220301_plain.json', lines=True, nrows = 100)\n",
    "\n",
    "# Dropping url-column\n",
    "df_prep.drop(columns=['url'], inplace=True, axis=1)\n",
    "display(df_prep.head())\n",
    "\n",
    "# Looking for missing / empty values\n",
    "print('\\nCheck first stats of first 10 rows')\n",
    "print('------------------------------------')\n",
    "print(df_prep.isna().sum().sort_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bb996",
   "metadata": {},
   "source": [
    "## __Cleaning and preprocessing textual data__\n",
    "- Converting to lower case\n",
    "- How to handle missing data (No necessaty...?)\n",
    "- Removing punctuations\n",
    "- Removing stopwords\n",
    "- Tokenizing data (especially last column with plain text)\n",
    "- Normalizing data (Stemming / Lemmatization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14678615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Concatenate Title with Plain-Text =========\n",
    "df_prep = df_prep.concat(['title', 'plain'])\n",
    "df_prep.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2956896a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>plain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52693423</td>\n",
       "      <td>Phidyle</td>\n",
       "      <td>phidyle is a genus of south american anyphaeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9553075</td>\n",
       "      <td>VMPS</td>\n",
       "      <td>vmps may refer to:\\n vivekanand memorial publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>55084366</td>\n",
       "      <td>1899 Sheriff of London Charity Shield</td>\n",
       "      <td>the 1899 sheriff of london charity shield was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>41934267</td>\n",
       "      <td>Christian-Social People's Party (Liechtenstein)</td>\n",
       "      <td>the christian-social people's party (), often ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17696798</td>\n",
       "      <td>1969 VFL Grand Final</td>\n",
       "      <td>the 1969 vfl grand final was an australian rul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            title  \\\n",
       "50  52693423                                          Phidyle   \n",
       "95   9553075                                             VMPS   \n",
       "82  55084366            1899 Sheriff of London Charity Shield   \n",
       "58  41934267  Christian-Social People's Party (Liechtenstein)   \n",
       "30  17696798                             1969 VFL Grand Final   \n",
       "\n",
       "                                                plain  \n",
       "50  phidyle is a genus of south american anyphaeni...  \n",
       "95  vmps may refer to:\\n vivekanand memorial publi...  \n",
       "82  the 1899 sheriff of london charity shield was ...  \n",
       "58  the christian-social people's party (), often ...  \n",
       "30  the 1969 vfl grand final was an australian rul...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= Lower case whole column =========\n",
    "df_prep['plain'] = df_prep['plain'].str.lower()\n",
    "df_prep.sample(frac = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d89b05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42       Roman Catholic Archdiocese of Cape Coast\n",
       "49                                 Paul Devautour\n",
       "77    Yugoslavia women's national basketball team\n",
       "3                                          Shuker\n",
       "24                                        Guignen\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['title'].sample(frac = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b3fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keith', 'richard', 'osik', 'born', 'october', '22', '1968', 'former', 'major', 'league', 'baseball', 'catcher', 'played', 'major', 'leagues', 'played', 'milwaukee', 'brewers', 'pittsburgh', 'pirates', 'baltimore', 'orioles', 'washington', 'nationals', 'drafted', '24th', 'round', 'mlb', 'draft', 'brother', 'also', 'professional', 'baseball', 'player', 'played', 'minors', 'born', 'port', 'washington', 'new', 'york', 'lives', 'shoreham', 'new', 'york', 'osik', 'currently', 'head', 'baseball', 'coach', 'farmingdale', 'state', 'college', 'division', 'iii', 'institution', 'located', 'long', 'island', 'new', 'york', 'inducted', 'suffolk', 'sports', 'hall', 'fame', 'long', 'island', 'baseball', 'category', 'class', '2008', 'external', 'links', '1968', 'births', 'living', 'people', 'major', 'league', 'baseball', 'catchers', 'baseball', 'players', 'new', 'york', 'state', 'people', 'port', 'washington', 'new', 'york', 'milwaukee', 'brewers', 'players', 'pittsburgh', 'pirates', 'players', 'baltimore', 'orioles', 'players', 'washington', 'nationals', 'players', 'buffalo', 'bisons', 'minor', 'league', 'players', 'nashville', 'sounds', 'players', 'durham', 'bulls', 'players', 'albuquerque', 'isotopes', 'players', 'new', 'orleans', 'zephyrs', 'players', 'farmingdale', 'state', 'rams', 'baseball', 'coaches']\n"
     ]
    }
   ],
   "source": [
    "# ========= Tokenization =========\n",
    "from nltk import word_tokenize\n",
    "test_doc = df_prep.iloc[0,2]\n",
    "test_doc_tokens = word_tokenize(test_doc)\n",
    "print(test_doc_tokens)\n",
    "\n",
    "def tokenize_words(plain_text):\n",
    "    tokenized_text = word_tokenize(plain_text)\n",
    "    return tokenized_text\n",
    "\n",
    "df_prep_tokenized = df_prep['plain'].apply(lambda x: tokenize_words(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f2c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Removing punctuations =========\n",
    "import string\n",
    "def remove_punctuations(plain_text):\n",
    "    punctiations = string.punctuation\n",
    "    return plain_text.translate(str.maketrans('', '', punctiations))\n",
    "\n",
    "df_prep['plain'] = df_prep['plain'].apply(lambda x : remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Removing stopwords =========\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def remove_stopwords(plain_text):\n",
    "    return ' '.join([word for word in plain_text.split() if word not in STOPWORDS])\n",
    "\n",
    "df_prep['plain'] = df_prep['plain'].apply(lambda x: remove_stopwords(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42e44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Removing special characters =========\n",
    "import re\n",
    "\n",
    "def remove_spec_char(plain_text):\n",
    "    plain_text = re.sub('[^a-zA-Z0-9]', ' ', plain_text)\n",
    "    plain_text = re.sub('\\s+', ' ', plain_text)\n",
    "    return plain_text\n",
    "\n",
    "df_prep['plain'] = df_prep['plain'].apply(lambda x : remove_spec_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8740a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ========= Stemming =========\n",
    "# For the Stemming we create a separate series which will append the last feature of the dataframe\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(plain_text):\n",
    "    return ' '.join([ps.stem(word) for word in plain_text.split()])\n",
    "\n",
    "df_prep['plain_stemmed'] = df_prep['plain'].apply(lambda x : stem_words(x))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0a0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/abderrahmanecharrade/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/abderrahmanecharrade/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ========= Lemmatization =========\n",
    "# For the Lemmatization we create a separate series which will append the last feature of the dataframe\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {'N':wordnet.NOUN, 'V':wordnet.VERB, 'J':wordnet.ADJ, 'R':wordnet.ADV}\n",
    "\n",
    "def lemmatize_word(plain_text):\n",
    "    # Finind pos tags\n",
    "    pos_text = pos_tag(plain_text.split())\n",
    "    return ' '.join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_text])\n",
    "\n",
    "df_prep['plain_lemmatized'] = df_prep['plain'].apply(lambda x : lemmatize_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267ca5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>plain</th>\n",
       "      <th>plain_stemmed</th>\n",
       "      <th>plain_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12148915</td>\n",
       "      <td>Keith Osik</td>\n",
       "      <td>keith richard osik born october 22 1968 former...</td>\n",
       "      <td>keith richard osik born octob 22 1968 former m...</td>\n",
       "      <td>keith richard osik born october 22 1968 former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16752449</td>\n",
       "      <td>Swansons Landing, Texas</td>\n",
       "      <td>swansons landing settlement former inland port...</td>\n",
       "      <td>swanson land settlement former inland port har...</td>\n",
       "      <td>swanson land settlement former inland port har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31967453</td>\n",
       "      <td>Mike Potts</td>\n",
       "      <td>mike michael potts may refer michael potts act...</td>\n",
       "      <td>mike michael pott may refer michael pott actor...</td>\n",
       "      <td>mike michael potts may refer michael potts act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47436994</td>\n",
       "      <td>Shuker</td>\n",
       "      <td>shuker surname notable people surname include ...</td>\n",
       "      <td>shuker surnam notabl peopl surnam includ abrah...</td>\n",
       "      <td>shuker surname notable people surname include ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13924699</td>\n",
       "      <td>William Clark (inventor)</td>\n",
       "      <td>william clark 17 march 1821 22 january 1880 en...</td>\n",
       "      <td>william clark 17 march 1821 22 januari 1880 en...</td>\n",
       "      <td>william clark 17 march 1821 22 january 1880 en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                     title  \\\n",
       "0  12148915                Keith Osik   \n",
       "1  16752449   Swansons Landing, Texas   \n",
       "2  31967453                Mike Potts   \n",
       "3  47436994                    Shuker   \n",
       "4  13924699  William Clark (inventor)   \n",
       "\n",
       "                                               plain  \\\n",
       "0  keith richard osik born october 22 1968 former...   \n",
       "1  swansons landing settlement former inland port...   \n",
       "2  mike michael potts may refer michael potts act...   \n",
       "3  shuker surname notable people surname include ...   \n",
       "4  william clark 17 march 1821 22 january 1880 en...   \n",
       "\n",
       "                                       plain_stemmed  \\\n",
       "0  keith richard osik born octob 22 1968 former m...   \n",
       "1  swanson land settlement former inland port har...   \n",
       "2  mike michael pott may refer michael pott actor...   \n",
       "3  shuker surnam notabl peopl surnam includ abrah...   \n",
       "4  william clark 17 march 1821 22 januari 1880 en...   \n",
       "\n",
       "                                    plain_lemmatized  \n",
       "0  keith richard osik born october 22 1968 former...  \n",
       "1  swanson land settlement former inland port har...  \n",
       "2  mike michael potts may refer michael potts act...  \n",
       "3  shuker surname notable people surname include ...  \n",
       "4  william clark 17 march 1821 22 january 1880 en...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_prep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c5c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed\n",
      "keith richard osik born octob 22 1968 former major leagu basebal catcher play major leagu play milwauke brewer pittsburgh pirat baltimor oriol washington nation draft 24th round mlb draft brother also profession basebal player play minor born port washington new york live shoreham new york osik current head basebal coach farmingdal state colleg divis iii institut locat long island new york induct suffolk sport hall fame long island basebal categori class 2008 extern link 1968 birth live peopl major leagu basebal catcher basebal player new york state peopl port washington new york milwauke brewer player pittsburgh pirat player baltimor oriol player washington nation player buffalo bison minor leagu player nashvil sound player durham bull player albuquerqu isotop player new orlean zephyr player farmingdal state ram basebal coach\n",
      "\n",
      "Lemmatized\n",
      "keith richard osik born october 22 1968 former major league baseball catcher play major league play milwaukee brewer pittsburgh pirate baltimore oriole washington national draft 24th round mlb draft brother also professional baseball player play minor bear port washington new york life shoreham new york osik currently head baseball coach farmingdale state college division iii institution locate long island new york inducted suffolk sport hall fame long island baseball category class 2008 external link 1968 birth live people major league baseball catcher baseball player new york state people port washington new york milwaukee brewer player pittsburgh pirate player baltimore oriole player washington national player buffalo bison minor league player nashville sound player durham bull player albuquerque isotopes player new orleans zephyrs player farmingdale state ram baseball coach\n"
     ]
    }
   ],
   "source": [
    "print('Stemmed')\n",
    "print(df_prep.iloc[0,3])\n",
    "print('\\nLemmatized')\n",
    "print(df_prep.iloc[0,4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b8891",
   "metadata": {},
   "source": [
    "# __Finished preprocessing__\n",
    "If the preprocessing fulfills the requirements for further operations and building IR-Models,\n",
    "export finished dataframe as csv or [__feather__]('https://arrow.apache.org/docs/python/feather.html') file format (light-weighted option to csv) which saves in comparison to json and csv more computation power and cpu time<br></br>\n",
    "Next task is to build up the vector space model and starting with tf-idf / term-weighting\n",
    "\n",
    "----------------------------------------------------------------\n",
    "## __Writing in feather file format__\n",
    "import pyarrow.feather as feather<br>\n",
    "feather.write_feather(df, '/path/to/file')\n",
    "\n",
    "## __Writing in csv file format__\n",
    "DataFrame.to_csv('/path/to/file')<br></br>\n",
    "\n",
    "If the size of the finished and exported file is still too large, add it to .gitignorefile<br>\n",
    "Github for private use (non-commercial) does not allows too large repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bbf3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit ('3.11.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3eb97f31843337c09a0fbe362ad0d1c57a4e5245c09f964828f772eab390a01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
